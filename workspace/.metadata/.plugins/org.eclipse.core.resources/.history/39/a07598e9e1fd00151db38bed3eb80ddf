package stubs;

import java.io.IOException;
import java.util.SortedMap;
import java.util.TreeMap;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.Mapper;

/**
 * Mapper's input are read from SequenceFile and records are: (K, V) where K is
 * a Text V is an Integer
 * 
 * @author Mahmoud Parsian
 *
 */
public class CountHighLowMapper extends Mapper<Text, Text, Text, IntWritable> {
	private IntWritable K2 = new IntWritable();
	private Text V2 = new Text();

	@Override
	public void map(Text key, Text value, Context context) throws IOException, InterruptedException {
		String movie_id = key.toString();
		double rating = Double.parseDouble(value.toString());
		String compositeValue = movie_id + "," + rating;
		top.put(rating, compositeValue);
		// keep only top N
		if (top.size() > N) {
			top.remove(top.firstKey());
		}
	}

	@Override
	protected void setup(Context context) throws IOException, InterruptedException {
		this.N = context.getConfiguration().getInt("N", 10); // default is top
																// 10
	}

	@Override
	protected void cleanup(Context context) throws IOException, InterruptedException {
		for (String str : top.values()) {
			value.set(str);
			context.write(nullkey, value);
		}
	}

}
